{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c3aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Dataset loaded successfully.\n",
      "  State  Account length  Area code International plan Voice mail plan  \\\n",
      "0    KS             128        415                 No             Yes   \n",
      "1    OH             107        415                 No             Yes   \n",
      "2    NJ             137        415                 No              No   \n",
      "3    OH              84        408                Yes              No   \n",
      "4    OK              75        415                Yes              No   \n",
      "\n",
      "   Number vmail messages  Total day minutes  Total day calls  \\\n",
      "0                     25              265.1              110   \n",
      "1                     26              161.6              123   \n",
      "2                      0              243.4              114   \n",
      "3                      0              299.4               71   \n",
      "4                      0              166.7              113   \n",
      "\n",
      "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
      "0             45.07              197.4               99             16.78   \n",
      "1             27.47              195.5              103             16.62   \n",
      "2             41.38              121.2              110             10.30   \n",
      "3             50.90               61.9               88              5.26   \n",
      "4             28.34              148.3              122             12.61   \n",
      "\n",
      "   Total night minutes  Total night calls  Total night charge  \\\n",
      "0                244.7                 91               11.01   \n",
      "1                254.4                103               11.45   \n",
      "2                162.6                104                7.32   \n",
      "3                196.9                 89                8.86   \n",
      "4                186.9                121                8.41   \n",
      "\n",
      "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
      "0                10.0                 3               2.70   \n",
      "1                13.7                 3               3.70   \n",
      "2                12.2                 5               3.29   \n",
      "3                 6.6                 7               1.78   \n",
      "4                10.1                 3               2.73   \n",
      "\n",
      "   Customer service calls  Churn  \n",
      "0                       1  False  \n",
      "1                       1  False  \n",
      "2                       0  False  \n",
      "3                       2  False  \n",
      "4                       3  False  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2666 entries, 0 to 2665\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   State                   2666 non-null   object \n",
      " 1   Account length          2666 non-null   int64  \n",
      " 2   Area code               2666 non-null   int64  \n",
      " 3   International plan      2666 non-null   object \n",
      " 4   Voice mail plan         2666 non-null   object \n",
      " 5   Number vmail messages   2666 non-null   int64  \n",
      " 6   Total day minutes       2666 non-null   float64\n",
      " 7   Total day calls         2666 non-null   int64  \n",
      " 8   Total day charge        2666 non-null   float64\n",
      " 9   Total eve minutes       2666 non-null   float64\n",
      " 10  Total eve calls         2666 non-null   int64  \n",
      " 11  Total eve charge        2666 non-null   float64\n",
      " 12  Total night minutes     2666 non-null   float64\n",
      " 13  Total night calls       2666 non-null   int64  \n",
      " 14  Total night charge      2666 non-null   float64\n",
      " 15  Total intl minutes      2666 non-null   float64\n",
      " 16  Total intl calls        2666 non-null   int64  \n",
      " 17  Total intl charge       2666 non-null   float64\n",
      " 18  Customer service calls  2666 non-null   int64  \n",
      " 19  Churn                   2666 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(3)\n",
      "memory usage: 398.5+ KB\n",
      "None\n",
      "Error: 'churn' column not found in the dataset. Please check the dataset structure.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'select_dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Identify categorical and numerical features\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Exclude 'state' and 'area code' as they might be high cardinality or not directly useful as numerical\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 'international plan' and 'voice mail plan' are categorical\u001b[39;00m\n\u001b[32m     39\u001b[39m categorical_features = [\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33marea code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minternational plan\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvoice mail plan\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m numerical_features = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_dtypes\u001b[49m(include=np.number).columns.tolist()\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Ensure that 'state' and 'area code' are treated as categorical if they exist\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33marea code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minternational plan\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvoice mail plan\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'select_dtypes'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# Load the dataset\n",
    "# The dataset is accessible via its contentFetchId\n",
    "try:\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(df.head())\n",
    "    print(df.info())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    # Exit if the dataset cannot be loaded\n",
    "    exit()\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "# Assuming 'churn' is the target variable\n",
    "if 'churn' in df.columns:\n",
    "    X = df.drop('churn', axis=1)\n",
    "    y = df['churn']\n",
    "    # Convert 'True.' and 'False.' to 1 and 0 for the target variable\n",
    "    y = y.map({'True.': 1, 'False.': 0})\n",
    "    print(\"\\nTarget variable 'churn' identified and preprocessed.\")\n",
    "else:\n",
    "    print(\"Error: 'churn' column not found in the dataset. Please check the dataset structure.\")\n",
    "    exit()\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "# Exclude 'state' and 'area code' as they might be high cardinality or not directly useful as numerical\n",
    "# 'international plan' and 'voice mail plan' are categorical\n",
    "categorical_features = ['state', 'area code', 'international plan', 'voice mail plan']\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Ensure that 'state' and 'area code' are treated as categorical if they exist\n",
    "for col in ['state', 'area code', 'international plan', 'voice mail plan']:\n",
    "    if col in X.columns and col not in categorical_features:\n",
    "        categorical_features.append(col)\n",
    "    if col in numerical_features:\n",
    "        numerical_features.remove(col)\n",
    "\n",
    "# Print identified features for verification\n",
    "print(f\"\\nNumerical features: {numerical_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nData split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).\")\n",
    "\n",
    "# Apply preprocessing to the training and testing data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get the number of features after one-hot encoding\n",
    "input_shape = X_train_processed.shape[1]\n",
    "print(f\"Input shape for the neural network: {input_shape} features.\")\n",
    "\n",
    "# Build the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # First hidden layer\n",
    "    tf.keras.layers.Dropout(0.3), # Dropout for regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    tf.keras.layers.Dropout(0.3), # Dropout for regularization\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nStarting model training...\")\n",
    "history = model.fit(X_train_processed, y_train,\n",
    "                    epochs=50, # Number of training epochs\n",
    "                    batch_size=32, # Batch size for training\n",
    "                    validation_split=0.2, # Use 20% of training data for validation\n",
    "                    verbose=1)\n",
    "print(\"Model training finished.\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nEvaluating model on the test set...\")\n",
    "loss, accuracy = model.evaluate(X_test_processed, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Visualize training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Visualize training and validation accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10716bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
