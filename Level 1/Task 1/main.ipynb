{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8755a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897c336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc2eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f79cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d45fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82be5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53b7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Loads, preprocesses, and splits the data from a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        sys.exit() # Exit the script if the file doesn't exist\n",
    "\n",
    "    print(\"--- Original Raw Dataset (first 5 rows) ---\")\n",
    "    print(df.head())\n",
    "\n",
    "    # --- Error Check: Verify the target column exists ---\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"\\n--- ERROR ---\")\n",
    "        print(f\"KeyError: The target column '{target_column}' was not found in the CSV file.\")\n",
    "        print(\"Please check for typos or extra spaces.\")\n",
    "        print(\"\\nAvailable columns are:\")\n",
    "        print(list(df.columns))\n",
    "        sys.exit() # Exit the script\n",
    "\n",
    "    print(\"\\nMissing values before processing:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Separate features (X) from the target variable (y)\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    # This assumes the positive class is 'Yes'. Modify if your labels are different (e.g., 1, 'positive').\n",
    "    y = df[target_column].apply(lambda x: 1 if str(x).lower() == 'yes' else 0)\n",
    "\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    print(f\"\\nNumerical features identified: {numerical_features}\")\n",
    "    print(f\"Categorical features identified: {categorical_features}\")\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"\\nDataset split into {X_train.shape[0]} training and {X_test.shape[0]} testing samples.\")\n",
    "\n",
    "    # Fit the preprocessor and transform the training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    # Transform the test data\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Get feature names after one-hot encoding for creating a readable DataFrame\n",
    "    try:\n",
    "        ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "        all_feature_names = numerical_features + list(ohe_feature_names)\n",
    "    except Exception:\n",
    "        # Fallback if there are no categorical features\n",
    "        all_feature_names = numerical_features\n",
    "\n",
    "    X_train_processed_df = pd.DataFrame(X_train_processed, columns=all_feature_names, index=X_train.index)\n",
    "    X_test_processed_df = pd.DataFrame(X_test_processed, columns=all_feature_names, index=X_test.index)\n",
    "\n",
    "    print(\"\\n--- Processed Training Features (first 5 rows) ---\")\n",
    "    print(X_train_processed_df.head())\n",
    "\n",
    "    print(\"\\n--- Processed Testing Features ---\")\n",
    "    print(X_test_processed_df)\n",
    "\n",
    "    print(\"\\n--- Shape of Processed Datasets ---\")\n",
    "    print(f\"Processed Training Features Shape: {X_train_processed_df.shape}\")\n",
    "    print(f\"Processed Testing Features Shape:  {X_test_processed_df.shape}\")\n",
    "    print(f\"Training Target Shape:             {y_train.shape}\")\n",
    "    print(f\"Testing Target Shape:              {y_test.shape}\")\n",
    "\n",
    "    return X_train_processed_df, X_test_processed_df, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aba6cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Raw Dataset (first 5 rows) ---\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Missing values before processing:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "\n",
      "Numerical features identified: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Categorical features identified: []\n",
      "\n",
      "Dataset split into 120 training and 30 testing samples.\n",
      "\n",
      "--- Processed Training Features (first 5 rows) ---\n",
      "    sepal_length  sepal_width  petal_length  petal_width\n",
      "22     -1.473937     1.220379     -1.563987    -1.309484\n",
      "15     -0.133071     3.020017     -1.277280    -1.042922\n",
      "65      1.085898     0.095606      0.385621     0.289886\n",
      "11     -1.230143     0.770470     -1.219939    -1.309484\n",
      "42     -1.717731     0.320560     -1.391963    -1.309484\n",
      "\n",
      "--- Processed Testing Features ---\n",
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "73       0.354517    -0.579258      0.557645     0.023324\n",
      "18      -0.133071     1.670289     -1.162597    -1.176203\n",
      "118      2.304867    -1.029168      1.819157     1.489413\n",
      "78       0.232620    -0.354304      0.442962     0.423166\n",
      "76       1.207795    -0.579258      0.614987     0.289886\n",
      "31      -0.498762     0.770470     -1.277280    -1.042922\n",
      "64      -0.254968    -0.354304     -0.073110     0.156605\n",
      "141      1.329692     0.095606      0.787011     1.489413\n",
      "68       0.476414    -1.928987      0.442962     0.423166\n",
      "82      -0.011174    -0.804213      0.098914     0.023324\n",
      "110      0.842104     0.320560      0.787011     1.089570\n",
      "12      -1.230143    -0.129349     -1.334622    -1.442764\n",
      "36      -0.376865     0.995425     -1.391963    -1.309484\n",
      "9       -1.108246     0.095606     -1.277280    -1.442764\n",
      "19      -0.864452     1.670289     -1.277280    -1.176203\n",
      "56       0.598311     0.545515      0.557645     0.556447\n",
      "104      0.842104    -0.129349      1.188401     1.356132\n",
      "69      -0.254968    -1.254122      0.098914    -0.109957\n",
      "55      -0.133071    -0.579258      0.442962     0.156605\n",
      "132      0.720208    -0.579258      1.073718     1.356132\n",
      "29      -1.352040     0.320560     -1.219939    -1.309484\n",
      "127      0.354517    -0.129349      0.672328     0.823009\n",
      "26      -0.986349     0.770470     -1.219939    -1.042922\n",
      "128      0.720208    -0.579258      1.073718     1.222851\n",
      "131      2.548661     1.670289      1.532449     1.089570\n",
      "145      1.085898    -0.129349      0.844352     1.489413\n",
      "108      1.085898    -1.254122      1.188401     0.823009\n",
      "143      1.207795     0.320560      1.245742     1.489413\n",
      "45      -1.230143    -0.129349     -1.334622    -1.176203\n",
      "30      -1.230143     0.095606     -1.219939    -1.309484\n",
      "\n",
      "--- Shape of Processed Datasets ---\n",
      "Processed Training Features Shape: (120, 4)\n",
      "Processed Testing Features Shape:  (30, 4)\n",
      "Training Target Shape:             (120,)\n",
      "Testing Target Shape:              (30,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    csv_file_name = 'data.csv'\n",
    "    target_column_name = 'species'\n",
    "    preprocess_data(file_path=csv_file_name, target_column=target_column_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
