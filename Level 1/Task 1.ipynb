{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8755a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f79cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path='data.csv'):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(\"--- Original Raw Dataset ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\nMissing values before processing:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    X = df.drop('purchased', axis=1)\n",
    "    y = df['purchased'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    print(f\"\\nNumerical features: {numerical_features}\")\n",
    "    print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"\\nDataset split into {X_train.shape[0]} training and {X_test.shape[0]} testing samples.\")\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "    all_feature_names = numerical_features + list(ohe_feature_names)\n",
    "\n",
    "    X_train_processed_df = pd.DataFrame(X_train_processed, columns=all_feature_names, index=X_train.index)\n",
    "    X_test_processed_df = pd.DataFrame(X_test_processed, columns=all_feature_names, index=X_test.index)\n",
    "\n",
    "    print(\"\\n--- Processed Training Features (first 5 rows) ---\")\n",
    "    print(X_train_processed_df.head())\n",
    "\n",
    "    print(\"\\n--- Processed Testing Features ---\")\n",
    "    print(X_test_processed_df)\n",
    "\n",
    "    print(\"\\n--- Shape of Processed Datasets ---\")\n",
    "    print(f\"Processed Training Features Shape: {X_train_processed_df.shape}\")\n",
    "    print(f\"Processed Testing Features Shape:  {X_test_processed_df.shape}\")\n",
    "    print(f\"Training Target Shape:             {y_train.shape}\")\n",
    "    print(f\"Testing Target Shape:              {y_test.shape}\")\n",
    "\n",
    "    return X_train_processed_df, X_test_processed_df, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    preprocess_data('data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
